{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":72631,"databundleVersionId":8021564,"sourceType":"competition"}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q -U langchain langchain-community chromadb sentence-transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Restart kernel (not factory reset!) for applying update transformers library","metadata":{}},{"cell_type":"code","source":"from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n\nimport torch\nfrom PIL import Image\n\nfrom transformers import BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nprocessor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\")\nprocessor.tokenizer.padding_side = \"left\"\nprocessor.tokenizer.pad_token_id = processor.tokenizer.eos_token_id\n\n# model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", load_in_4bit=True, device_map=\"auto\")\nmodel = LlavaNextForConditionalGeneration.from_pretrained(\n    \"llava-hf/llava-v1.6-mistral-7b-hf\",\n    quantization_config=quantization_config,\n    device_map=\"auto\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:06:54.069452Z","iopub.execute_input":"2024-03-31T12:06:54.069761Z","iopub.status.idle":"2024-03-31T12:10:31.479927Z","shell.execute_reply.started":"2024-03-31T12:06:54.069723Z","shell.execute_reply":"2024-03-31T12:10:31.478765Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-31 12:07:03.965081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-31 12:07:03.965221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-31 12:07:04.119977: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/754 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaed73dbe2a6433088851857acd823c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e03031ec27e843a9adf0873c8c234092"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d24f23637c64cb49a5731db678921c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8dfb1daf8c49feabb4e785748c74f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"459f10fb04994b698f822ecb7866ae77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eb0a3f828944a86af8eb2bc23f16792"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaa510b513494341bbe3f23f63867c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/70.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e75f9c655094fc59956db966fbb828a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9190e91fc40e472b80a915cfe7ceb000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca2ef9eca9834178b2b9d141f1dfff29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7359803e1b743f6a0b24b399b79babe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11429844588428197d1696abb8e58f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e82ee34e72418e9f073061f865c53c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4e78c33a54c4593b2648b10fff1e9f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1e273da9a94b88815c1bac2c056730"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nroot_path = Path('/kaggle/input/qa-over-slides-searching-for-the-information')\ntrain_path = root_path.joinpath('train/train')\ntest_path = root_path.joinpath('test/test')\n\ndeck_image_summaries = {}\n\nwith open(root_path.joinpath('qa_train.jsonl')) as json_file:\n    qa_data = [json.loads(line) for line in json_file]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:38.426424Z","iopub.execute_input":"2024-03-31T12:10:38.427772Z","iopub.status.idle":"2024-03-31T12:10:39.463064Z","shell.execute_reply.started":"2024-03-31T12:10:38.427728Z","shell.execute_reply":"2024-03-31T12:10:39.462173Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def image_summarize(image, prompt, max_new_tokens=128):\n    \"\"\"Make image summary\"\"\"\n    inputs = processor(prompt, image, return_tensors=\"pt\").to(\"cuda\")\n\n    output = model.generate(**inputs, max_new_tokens=max_new_tokens, pad_token_id=processor.tokenizer.eos_token_id)\n    return processor.decode(output[0], skip_special_tokens=True).split(\"[/INST]\")[1].strip()\n    \n\ndef generate_img_summaries(images):\n    \"\"\"\n    Generate summaries for images\n\n    :param img_base64_list: Base64 encoded images\n    :return: List of image summaries and processed images\n    \"\"\"\n\n    # Store image summaries\n    image_summaries = []\n\n    # Prompt\n    prompt = \"\"\"[INST] <image>\\nYou are an assistant tasked with summarizing images for retrieval.\nThese summaries will be embedded and used to retrieve the raw image.\nGive a concise summary of the image that is well optimized for retrieval. [/INST]\"\"\"\n\n    # Apply summarization to images\n    for i, image in enumerate(images):\n        try:\n            image_summaries.append(image_summarize(image, prompt))\n        except:\n            print(f\"BadRequestError with image {i+1}\")\n\n    return image_summaries","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:40.571907Z","iopub.execute_input":"2024-03-31T12:10:40.572694Z","iopub.status.idle":"2024-03-31T12:10:40.581451Z","shell.execute_reply.started":"2024-03-31T12:10:40.572657Z","shell.execute_reply":"2024-03-31T12:10:40.580363Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import uuid\n\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.retrievers.multi_vector import MultiVectorRetriever\nfrom langchain.schema.document import Document\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.schema.runnable import RunnableLambda, RunnablePassthrough\nfrom langchain.storage import InMemoryStore\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n\ndef create_multi_vector_retriever(image_summaries, images):\n    \"\"\"\n    Create retriever that indexes summaries, but returns raw images or texts\n\n    :param vectorstore: Vectorstore to store embedded image sumamries\n    :param image_summaries: Image summaries\n    :param images: Base64 encoded images\n    :return: Retriever\n    \"\"\"\n\n    # Initialize the storage layer\n    store = InMemoryStore()\n    id_key = \"doc_id\"\n    \n    img_ids = [str(uuid.uuid4()) for _ in image_summaries]\n    summary_img = [\n        Document(page_content=s, metadata={id_key: img_ids[i]})\n        for i, s in enumerate(image_summaries)\n    ]\n    \n    model_name = \"colbert-ir/colbertv2.0\"\n    embedding_function = HuggingFaceEmbeddings(model_name=model_name)\n\n    # The vectorstore to use to index the summaries\n    Chroma().delete_collection()\n    vectorstore = Chroma.from_documents(summary_img, embedding_function)\n\n    # Create the multi-vector retriever\n    retriever = MultiVectorRetriever(\n        vectorstore=vectorstore,\n        docstore=store,\n        id_key=id_key,\n    )\n    \n    retriever.vectorstore.add_documents(summary_img)\n    retriever.docstore.mset(\n        list(zip(img_ids, images))\n    )  # Store the image summary as the raw document\n\n    return retriever","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:41.247944Z","iopub.execute_input":"2024-03-31T12:10:41.248319Z","iopub.status.idle":"2024-03-31T12:10:43.409939Z","shell.execute_reply.started":"2024-03-31T12:10:41.248288Z","shell.execute_reply":"2024-03-31T12:10:43.409106Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def llava_generate(_dict, prompt=None):\n    image = _dict['image'][0]\n    prompt = f\"\"\"[INST] <image>\nYou are an analyst tasked with answering questions about visual content.\nYou will be given a image from a slide deck / presentation.\nUse this information to answer the user question.\nGive a short, precise answer.\nUser-provided question: {_dict['question']}\nAnswer: [/INST]\"\"\"\n    return image_summarize(image, prompt, max_new_tokens=256)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:43.411408Z","iopub.execute_input":"2024-03-31T12:10:43.411710Z","iopub.status.idle":"2024-03-31T12:10:43.416910Z","shell.execute_reply.started":"2024-03-31T12:10:43.411686Z","shell.execute_reply":"2024-03-31T12:10:43.415866Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def multi_modal_rag_chain(retriever):\n    \"\"\"\n    Multi-modal RAG chain\n    \"\"\"\n\n    # RAG pipeline\n    chain = (\n        {\n            \"image\": retriever,\n            \"question\": RunnablePassthrough(),\n        }\n        | RunnableLambda(llava_generate)\n        | StrOutputParser()\n    )\n\n    return chain","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:43.417970Z","iopub.execute_input":"2024-03-31T12:10:43.418227Z","iopub.status.idle":"2024-03-31T12:10:43.435841Z","shell.execute_reply.started":"2024-03-31T12:10:43.418204Z","shell.execute_reply":"2024-03-31T12:10:43.434910Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def predict(sample, deck_image_summaries, data_dir_path=train_path):\n    question = sample['question']\n    deck_name = sample['deck_name']\n    \n    dataset = load_dataset(\"imagefolder\", data_dir=data_dir_path.joinpath(deck_name))\n    images = dataset['train']['image']\n    \n    if deck_name not in deck_image_summaries:\n        deck_image_summaries[deck_name] = generate_img_summaries(images)\n        \n    image_summaries = deck_image_summaries[deck_name]\n\n    # Create retriever\n    retriever_multi_vector_img = create_multi_vector_retriever(\n        image_summaries,\n        images,\n    )\n    \n    chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img)\n    return chain_multimodal_rag.invoke(question)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:11:53.805081Z","iopub.execute_input":"2024-03-31T12:11:53.805531Z","iopub.status.idle":"2024-03-31T12:11:53.813516Z","shell.execute_reply.started":"2024-03-31T12:11:53.805496Z","shell.execute_reply":"2024-03-31T12:11:53.812281Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def normalize_text(s):\n    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n    import string, re\n\n    def remove_articles(text):\n        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n        return re.sub(regex, \" \", text)\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\ndef compute_exact_match(prediction, truth):\n    return int(normalize_text(prediction) == normalize_text(truth))\n\ndef compute_f1(prediction, truth):\n    pred_tokens = normalize_text(prediction).split()\n    truth_tokens = normalize_text(truth).split()\n    \n    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n        return int(pred_tokens == truth_tokens)\n    \n    common_tokens = set(pred_tokens) & set(truth_tokens)\n    \n    # if there are no common tokens then f1 = 0\n    if len(common_tokens) == 0:\n        return 0\n    \n    prec = len(common_tokens) / len(pred_tokens)\n    rec = len(common_tokens) / len(truth_tokens)\n    \n    return 2 * (prec * rec) / (prec + rec)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:44.414037Z","iopub.execute_input":"2024-03-31T12:10:44.414725Z","iopub.status.idle":"2024-03-31T12:10:44.425019Z","shell.execute_reply.started":"2024-03-31T12:10:44.414692Z","shell.execute_reply":"2024-03-31T12:10:44.424024Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# n_samples = 10\n\n# pred_answers = []\n# f1_scores = []\n\n# for sample in tqdm(qa_data[0:n_samples]):\n#     pred_answer = predict(sample)\n#     true_answer = sample['answer']\n#     f1_score = compute_f1(pred_answer, true_answer)\n    \n#     pred_answers.append(pred_answer)\n#     f1_scores.append(f1_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:45.520879Z","iopub.execute_input":"2024-03-31T12:10:45.521783Z","iopub.status.idle":"2024-03-31T12:10:45.525976Z","shell.execute_reply.started":"2024-03-31T12:10:45.521748Z","shell.execute_reply":"2024-03-31T12:10:45.524833Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# for i, sample in enumerate(qa_data[0:n_samples]):\n#     print(\"\\tSample\", i)\n#     print(\"QUESTION:\\n\\t\", sample['question'])\n#     print(\"PREDICT ANSWER:\\n\\t\", pred_answers[i])\n#     print(\"TRUE ANSWER:\\n\\t\", sample['answer'])\n#     print(\"F1 SCORE:\", f1_scores[i])\n#     print(\"---------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:46.210542Z","iopub.execute_input":"2024-03-31T12:10:46.211445Z","iopub.status.idle":"2024-03-31T12:10:46.215500Z","shell.execute_reply.started":"2024-03-31T12:10:46.211411Z","shell.execute_reply":"2024-03-31T12:10:46.214454Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntest = pd.read_csv(root_path.joinpath('qa_test.csv'))\nprint(\"Test shape:\", test.shape)\n\ntest_sorted = test.sort_values(by='deck_name')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:54.547828Z","iopub.execute_input":"2024-03-31T12:10:54.548559Z","iopub.status.idle":"2024-03-31T12:10:54.597556Z","shell.execute_reply.started":"2024-03-31T12:10:54.548519Z","shell.execute_reply":"2024-03-31T12:10:54.596589Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Test shape: (1014, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\n\nn_samples_test = 10\n\ntest_deck_image_summaries = {}\ntest_pred_answers = []\n\noutput_path = Path('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:10:58.692834Z","iopub.execute_input":"2024-03-31T12:10:58.693208Z","iopub.status.idle":"2024-03-31T12:10:58.698283Z","shell.execute_reply.started":"2024-03-31T12:10:58.693177Z","shell.execute_reply":"2024-03-31T12:10:58.697225Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(n_samples_test)):\n    sample = test_sorted.iloc[i]\n    pred_answer = predict(sample, test_deck_image_summaries, data_dir_path=test_path)\n    test_pred_answers.append(pred_answer)\n    \n    with open(output_path.joinpath('qa_test_deck_summaries.csv'), 'a') as file:\n        writer = csv.DictWriter(file, fieldnames=['deck_name', 'slide_summaries'])\n        writer.writerow({'deck_name': sample['deck_name'], \n                         'slide_summaries': test_deck_image_summaries[sample['deck_name']]})\n    \n    with open(output_path.joinpath('qa_sample_submission.csv'), 'a') as file:\n        writer = csv.DictWriter(file, fieldnames=['ID', 'pred_answer'])\n        writer.writerow({'ID': sample['ID'], 'pred_answer': pred_answer})","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:24:30.827177Z","iopub.execute_input":"2024-03-31T12:24:30.827600Z","iopub.status.idle":"2024-03-31T12:29:03.470530Z","shell.execute_reply.started":"2024-03-31T12:24:30.827564Z","shell.execute_reply":"2024-03-31T12:29:03.469342Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ac9107234464e8c82af3d1d32f94d85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99cefde8c8074ece823a741a72d3f132"}},"metadata":{}},{"name":"stderr","text":" 10%|█         | 1/10 [00:10<01:30, 10.08s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cd8ca11958542af8a137b1768b83b91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06620212243642ab9c7830bcc4dcd071"}},"metadata":{}},{"name":"stderr","text":" 20%|██        | 2/10 [00:14<00:55,  6.94s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14ebfb142744252b224c3805960e155"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset image_folder/default to /root/.cache/huggingface/datasets/image_folder/default-a809ff933bc29276/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091...\n                ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files #5:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a665b4354d7e40dba0ba86b27ba49e64"}},"metadata":{}},{"name":"stderr","text":" 30%|███       | 3/10 [03:50<11:55, 102.20s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d92211535a7f4e6da4a20a0b366fef33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da542e8e196477fab41dbd2a88627d9"}},"metadata":{}},{"name":"stderr","text":" 40%|████      | 4/10 [03:57<06:28, 64.70s/it] ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e1b11e9cae473f8d6aae95b50ebbc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaf83e7728444f71b32b2218f089d27f"}},"metadata":{}},{"name":"stderr","text":" 50%|█████     | 5/10 [04:05<03:40, 44.10s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19c7ef1c3d694ddc87dfb87b08e3c548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d68caaf048949c88e7d2fbc2485b22a"}},"metadata":{}},{"name":"stderr","text":" 60%|██████    | 6/10 [04:09<02:02, 30.72s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a760b0bb1f65448bb5b65c9ccd289a9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d81263ff59f42b9b9418ec4793cc4d7"}},"metadata":{}},{"name":"stderr","text":" 70%|███████   | 7/10 [04:14<01:06, 22.24s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c781e3c12e0e4da980d4e2175cabf621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"169455022a704dfc835cba297829196e"}},"metadata":{}},{"name":"stderr","text":" 80%|████████  | 8/10 [04:19<00:33, 16.64s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef92fe43d7794e9293b7a39c4632f430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fcc687c78de44a8b013a390ab3382c4"}},"metadata":{}},{"name":"stderr","text":" 90%|█████████ | 9/10 [04:27<00:14, 14.14s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5627185566c44b1b52582e310576d59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55519c3358d41c484d840494cc659ad"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 10/10 [04:32<00:00, 27.26s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"n_start, n_end = 10, 100\nfor i in range(n_start, n_end):\n    sample = test_sorted.iloc[i]\n    pred_answer = predict(sample, test_deck_image_summaries, data_dir_path=test_path)\n    test_pred_answers.append(pred_answer)\n    \n    with open(output_path.joinpath('qa_test_deck_summaries.csv'), 'a') as file:\n        writer = csv.DictWriter(file, fieldnames=['deck_name', 'slide_summaries'])\n        writer.writerow({'deck_name': sample['deck_name'], \n                         'slide_summaries': test_deck_image_summaries[sample['deck_name']]})\n    \n    with open(output_path.joinpath('qa_sample_submission.csv'), 'a') as file:\n        writer = csv.DictWriter(file, fieldnames=['ID', 'pred_answer'])\n        writer.writerow({'ID': sample['ID'], 'pred_answer': pred_answer})","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:44:37.906400Z","iopub.execute_input":"2024-03-31T12:44:37.907209Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/90 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"185f856417554f979e40d312877fbb5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d03c3288a0c4ecaa7731eb3f942fbf7"}},"metadata":{}},{"name":"stderr","text":"  1%|          | 1/90 [00:04<07:22,  4.98s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3759537421af49ca83438c9aace0ce6e"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset image_folder/default to /root/.cache/huggingface/datasets/image_folder/default-7535e2526ce358a4/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091...\n                ","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.read_csv(output_path.joinpath('qa_sample_submission.csv'), names=['ID', 'pred_answer'], header=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:35:26.655861Z","iopub.execute_input":"2024-03-31T12:35:26.656579Z","iopub.status.idle":"2024-03-31T12:35:26.668675Z","shell.execute_reply.started":"2024-03-31T12:35:26.656546Z","shell.execute_reply":"2024-03-31T12:35:26.666214Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"    ID                                        pred_answer\n0  299  In the image, the \"No Delegation Tokens\" diagr...\n1  672  The two components of the Container request ar...\n2  579  The transparent process of land acquisitions i...\n3  580  The image shows a diagram of the institutional...\n4  590  The image shows the following levels of instit...\n5  485        Old Act Section 4 is in New Act Section 11.\n6  839  The 2013 LARR Act made no provision about soci...\n7  766  SIA stands for \"Society of Industrial and Appl...\n8  765  The content of Chapter IV includes determinati...\n9  982  The 1894 Act did not specify compensation for ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>pred_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>299</td>\n      <td>In the image, the \"No Delegation Tokens\" diagr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>672</td>\n      <td>The two components of the Container request ar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>579</td>\n      <td>The transparent process of land acquisitions i...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>580</td>\n      <td>The image shows a diagram of the institutional...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>590</td>\n      <td>The image shows the following levels of instit...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>485</td>\n      <td>Old Act Section 4 is in New Act Section 11.</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>839</td>\n      <td>The 2013 LARR Act made no provision about soci...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>766</td>\n      <td>SIA stands for \"Society of Industrial and Appl...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>765</td>\n      <td>The content of Chapter IV includes determinati...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>982</td>\n      <td>The 1894 Act did not specify compensation for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}