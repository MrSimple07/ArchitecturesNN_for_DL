{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeMLmAdu3z6/Yh6xMgY/8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrSimple07/ArchitecturesNN_for_DL/blob/main/CTPromptiongDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "client = os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "Wz40jfZb_-8P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = \"Start a chain of thoughts about the topic of artificial intelligence:\"\n",
        "\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, max_length=100, do_sample=True, temperature=0.7)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"GPT-2:\", response)\n",
        "\n",
        "prompt += \"\\n\\nContinuing the chain: \" + response\n",
        "\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, max_length=200, do_sample=True, temperature=0.7)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"GPT-2:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n05wqScAnKj",
        "outputId": "f7d61f0c-d904-4a80-d625-7854294ee6c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-2: Start a chain of thoughts about the topic of artificial intelligence:\n",
            "\n",
            "As I mentioned earlier, I'm a big proponent of AI. I have been a big proponent of AI for years. I'm a big proponent of Artificial Intelligence. I really believe in it. I really believe in it. I think the technology will change and eventually, we're going to have a technology that's going to replace us.\n",
            "\n",
            "But why?\n",
            "\n",
            "This is a great question, and it's an interesting\n",
            "GPT-2: Start a chain of thoughts about the topic of artificial intelligence:\n",
            "\n",
            "Continuing the chain: Start a chain of thoughts about the topic of artificial intelligence:\n",
            "\n",
            "As I mentioned earlier, I'm a big proponent of AI. I have been a big proponent of AI for years. I'm a big proponent of Artificial Intelligence. I really believe in it. I really believe in it. I think the technology will change and eventually, we're going to have a technology that's going to replace us.\n",
            "\n",
            "But why?\n",
            "\n",
            "This is a great question, and it's an interesting one.\n",
            "\n",
            "In my case, I do believe that what is happening is that we're going to be able to do something about artificial intelligence.\n",
            "\n",
            "I'm not sure I would say AI is going to replace us. Sure, there are a lot of very smart people at the top of the food chain. But I also believe that we are going to have to do something. And I think\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the total distance covered\n"
      ],
      "metadata": {
        "id": "TJa0IcbhG5Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Calculate the total distance covered.\"\n",
        "\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, max_length=50, do_sample=True, temperature=0.7)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Step 1:\", response)\n",
        "\n",
        "prompt += \"\\n\\nCalculate the total time taken.\"\n",
        "\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, max_length=50, do_sample=True, temperature=0.7)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Step 2:\", response)\n",
        "\n",
        "prompt += \"\\n\\nCalculate the average speed using the formula: Average Speed = Total Distance / Total Time.\"\n",
        "\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, max_length=100, do_sample=True, temperature=0.7)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Step 3:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBSscrfrAtcX",
        "outputId": "34b3ee91-69ef-49aa-b942-030afadb5ca5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Calculate the total distance covered. It is a simple formula for this: the distance to the sun at a particular point in the sky (on a specific season) is called the latitude divided by the longitude. For example, if you want\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2: Calculate the total distance covered.\n",
            "\n",
            "Calculate the total time taken.\n",
            "\n",
            "Calculate the total number of steps covered.\n",
            "\n",
            "Calculate the total number of steps left.\n",
            "\n",
            "Calculate the total number\n",
            "Step 3: Calculate the total distance covered.\n",
            "\n",
            "Calculate the total time taken.\n",
            "\n",
            "Calculate the average speed using the formula: Average Speed = Total Distance / Total Time.\n",
            "\n",
            "Calculate the average speed using the formula: Average Speed = Total Time / Total Times.\n",
            "\n",
            "Calculate the average speed using the formula: Average Speed = Total Time / Total Times.\n",
            "\n",
            "Calculate the average speed using the formula: Average Speed = Total Time / Total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYSDtaHyF3Up"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}